{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Lưu mô hình\n",
    "\n",
    "\n",
    "# Tải lại mô hình\n",
    "model = tf.keras.models.load_model('CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "import numpy as np\n",
    "def remove_sil(path_in, path_out, format=\"wav\"):\n",
    "    sound = AudioSegment.from_file(path_in, format=format)\n",
    "    non_sil_times = detect_nonsilent(sound, min_silence_len=50, silence_thresh=sound.dBFS * 1.5)\n",
    "    if len(non_sil_times) > 0:\n",
    "        non_sil_times_concat = [non_sil_times[0]]\n",
    "        if len(non_sil_times) > 1:\n",
    "            for t in non_sil_times[1:]:\n",
    "                if t[0] - non_sil_times_concat[-1][-1] < 50:\n",
    "                    non_sil_times_concat[-1][-1] = t[1]\n",
    "                else:\n",
    "                    non_sil_times_concat.append(t)\n",
    "        non_sil_times = [t for t in non_sil_times_concat if t[1] - t[0] > 80]\n",
    "        sound[non_sil_times[0][0]: non_sil_times[-1][1]].export(path_out, format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_audio(audio_binary):\n",
    "      # Decode WAV-encoded audio files to `float32` tensors, normalized\n",
    "  # to the [-1.0, 1.0] range. Return `float32` audio and a sample rate.\n",
    "  audio, _ = tf.audio.decode_wav(contents=audio_binary)\n",
    "  # Since all the data is single channel (mono), drop the `channels`\n",
    "  # axis from the array.\n",
    "  return tf.squeeze(audio, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform):\n",
    "      # Zero-padding for an audio waveform with less than 16,000 samples.\n",
    "  input_len = 32000\n",
    "  waveform = waveform[:input_len]\n",
    "  # Cast the waveform tensors' dtype to float32.\n",
    "  waveform = tf.cast(waveform, dtype=tf.float32)\n",
    "  # Convert the waveform to a spectrogram via a STFT.\n",
    "  spectrogram = tf.signal.stft(\n",
    "      waveform, frame_length=256, frame_step=128)\n",
    "  # Obtain the magnitude of the STFT.\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  # Add a `channels` dimension, so that the spectrogram can be used\n",
    "  # as image-like input data with convolution layers (which expect\n",
    "  # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "  spectrogram = spectrogram[..., tf.newaxis]\n",
    "  # Resize the spectrogram to a fixed size (e.g., 224x224).\n",
    "  spectrogram = tf.image.resize(spectrogram, size=(240, 240))\n",
    "  return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = ['batden', 'batdieuhoa', 'batquat', 'dongcua', 'giamtocdoquat', 'mocua', 'tangtocdoquat', 'tatden', 'tatdieuhoa', 'tatquat']\n",
    "commands = np.array(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading audio file...\n",
      "audio file read!\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "Predicted label: batdieuhoa\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "# đọc file \n",
    "record()\n",
    "\n",
    "# remove_silence(WAVE_OUTPUT_FILENAME)\n",
    "remove_sil(\"new_audio.wav\",\"audio.wav\")\n",
    "\n",
    "# Đọc file âm thanh đã cắt\n",
    "new_audio_binary = tf.io.read_file(\"audio.wav\")\n",
    "new_waveform = decode_audio(new_audio_binary)\n",
    "new_spectrogram = get_spectrogram(new_waveform)\n",
    "new_spectrogram = tf.expand_dims(new_spectrogram, axis=0)\n",
    "predictions = model.predict(new_spectrogram)\n",
    "\n",
    "# Chuyển đổi các xác suất thành nhãn\n",
    "predicted_label_id = np.argmax(predictions[0])\n",
    "predicted_label = commands[predicted_label_id]\n",
    "\n",
    "print('Predicted label:', predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record():\n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 16000\n",
    "    RECORD_SECONDS = 6\n",
    "    WAVE_OUTPUT_FILENAME = \"new_audio.wav\"\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "\n",
    "\n",
    "    frames = []\n",
    "\n",
    "\n",
    "    print('reading audio file...')\n",
    "    with wave.open('new_audio.wav', 'rb') as wf:\n",
    "        for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = wf.readframes(CHUNK)\n",
    "            frames.append(data)\n",
    "\n",
    "\n",
    "\n",
    "    print('audio file read!')\n",
    "\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
