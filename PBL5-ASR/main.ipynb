{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from IPython import display"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commands: ['batden' 'batdieuhoa' 'batquat' 'dongcua' 'giamtocdoquat' 'mocua'\n",
      " 'tangtocdoquat' 'tatden' 'tatdieuhoa' 'tatquat']\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = 'data_cuted'\n",
    "data_dir = pathlib.Path(DATASET_PATH)\n",
    "commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "print('Commands:', commands)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_nonsilent\n",
    "\n",
    "def remove_sil(path_in, path_out, format=\"wav\"):\n",
    "    sound = AudioSegment.from_file(path_in, format=format)\n",
    "    non_sil_times = detect_nonsilent(sound, min_silence_len=50, silence_thresh=sound.dBFS * 1.25)\n",
    "    if len(non_sil_times) > 0:\n",
    "        non_sil_times_concat = [non_sil_times[0]]\n",
    "        if len(non_sil_times) > 1:\n",
    "            for t in non_sil_times[1:]:\n",
    "                if t[0] - non_sil_times_concat[-1][-1] < 50:\n",
    "                    non_sil_times_concat[-1][-1] = t[1]\n",
    "                else:\n",
    "                    non_sil_times_concat.append(t)\n",
    "        non_sil_times = [t for t in non_sil_times_concat if t[1] - t[0] > 80]\n",
    "        sound[non_sil_times[0][0]: non_sil_times[-1][1]].export(path_out, format='wav')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def decode_audio(audio_binary):\n",
    "  # Decode WAV-encoded audio files to `float32` tensors, normalized\n",
    "  # to the [-1.0, 1.0] range. Return `float32` audio and a sample rate.\n",
    "  audio, _ = tf.audio.decode_wav(contents=audio_binary)\n",
    "  # Since all the data is single channel (mono), drop the `channels`\n",
    "  # axis from the array.\n",
    "  return tf.squeeze(audio, axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform):\n",
    "  input_len = 32000\n",
    "  waveform = waveform[:input_len]\n",
    "  # Cast the waveform tensors' dtype to float32.\n",
    "  waveform = tf.cast(waveform, dtype=tf.float32)\n",
    "  # Convert the waveform to a spectrogram via a STFT.\n",
    "  spectrogram = tf.signal.stft(\n",
    "      waveform, frame_length=256, frame_step=128)\n",
    "  # Obtain the magnitude of the STFT.\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "  # Add a `channels` dimension, so that the spectrogram can be used\n",
    "  # as image-like input data with convolution layers (which expect\n",
    "  # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "  spectrogram = spectrogram[..., tf.newaxis]\n",
    "  # Resize the spectrogram to a fixed size (e.g., 224x224).\n",
    "  spectrogram = tf.image.resize(spectrogram, size=(256, 256))\n",
    "  return spectrogram"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def plot_spectrogram(spectrogram, ax):\n",
    "  if len(spectrogram.shape) > 2:\n",
    "    assert len(spectrogram.shape) == 3\n",
    "    spectrogram = np.squeeze(spectrogram, axis=-1)\n",
    "  # Convert the frequencies to log scale and transpose, so that the time is\n",
    "  # represented on the x-axis (columns).\n",
    "  # Add an epsilon to avoid taking a log of zero.\n",
    "  log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n",
    "  height = log_spec.shape[0]\n",
    "  width = log_spec.shape[1]\n",
    "  X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
    "  Y = range(height)\n",
    "  ax.pcolormesh(X, Y, log_spec)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('CNN_final2.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu ghi âm...\n",
      "Đã ghi âm xong!\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "15.376972\n",
      "-9.575705\n",
      "5.8645434\n",
      "11.289575\n",
      "Sai rồi em ơi\n",
      "Predicted label: batden\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = 512\n",
    "RECORD_SECONDS = 2\n",
    "WAVE_OUTPUT_FILENAME = \"new_audio.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# Tìm kiếm thiết bị âm thanh\n",
    "for i in range(p.get_device_count()):\n",
    "    dev = p.get_device_info_by_index(i)\n",
    "    if 'Microphone' in dev['name']:\n",
    "        device_name = dev['name']\n",
    "        break\n",
    "print('Bắt đầu ghi âm...')\n",
    "# Khởi tạo stream\n",
    "stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, input_device_index=i, frames_per_buffer=CHUNK)\n",
    "\n",
    "# Ghi âm\n",
    "frames = []\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print('Đã ghi âm xong!')\n",
    "\n",
    "# Dừng stream\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "# Lưu file âm thanh\n",
    "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n",
    "\n",
    "# remove_silence(WAVE_OUTPUT_FILENAME)\n",
    "remove_sil(\"new_audio.wav\",\"audio.wav\")\n",
    "\n",
    "# Đọc file âm thanh đã cắt\n",
    "new_audio_binary = tf.io.read_file(\"audio.wav\")\n",
    "new_waveform = decode_audio(new_audio_binary)\n",
    "new_spectrogram = get_spectrogram(new_waveform)\n",
    "new_spectrogram = tf.expand_dims(new_spectrogram, axis=0)\n",
    "predictions = model.predict(new_spectrogram)\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "# Chuyển đổi các xác suất thành nhãn\n",
    "predicted_label_id = np.argmax(predictions[0])\n",
    "predicted_label = commands[predicted_label_id]\n",
    "\n",
    "print('Predicted label:', predicted_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_spectrogram(new_spectrogram.numpy().reshape(new_spectrogram.shape[1], new_spectrogram.shape[2]), ax)\n",
    "ax.set(title='Spectrogram')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}