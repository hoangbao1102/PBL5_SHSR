{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 26\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.png\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m     25\u001B[0m     filepath \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(dirpath, filename)\n\u001B[1;32m---> 26\u001B[0m     image \u001B[38;5;241m=\u001B[39m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m     images\u001B[38;5;241m.\u001B[39mappend(image)\n\u001B[0;32m     28\u001B[0m     labels\u001B[38;5;241m.\u001B[39mappend(class_to_index[class_name])\n",
      "File \u001B[1;32mD:\\Learn_Py\\DataSci\\venv\\lib\\site-packages\\matplotlib\\pyplot.py:2131\u001B[0m, in \u001B[0;36mimread\u001B[1;34m(fname, format)\u001B[0m\n\u001B[0;32m   2129\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(matplotlib\u001B[38;5;241m.\u001B[39mimage\u001B[38;5;241m.\u001B[39mimread)\n\u001B[0;32m   2130\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mimread\u001B[39m(fname, \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m-> 2131\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmatplotlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Learn_Py\\DataSci\\venv\\lib\\site-packages\\matplotlib\\image.py:1542\u001B[0m, in \u001B[0;36mimread\u001B[1;34m(fname, format)\u001B[0m\n\u001B[0;32m   1536\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1537\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease open the URL for reading and pass the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1538\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresult to Pillow, e.g. with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1540\u001B[0m         )\n\u001B[0;32m   1541\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m img_open(fname) \u001B[38;5;28;01mas\u001B[39;00m image:\n\u001B[1;32m-> 1542\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[43m_pil_png_to_float_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(image, PIL\u001B[38;5;241m.\u001B[39mPngImagePlugin\u001B[38;5;241m.\u001B[39mPngImageFile) \u001B[38;5;28;01melse\u001B[39;00m\n\u001B[0;32m   1544\u001B[0m             pil_to_array(image))\n",
      "File \u001B[1;32mD:\\Learn_Py\\DataSci\\venv\\lib\\site-packages\\matplotlib\\image.py:1731\u001B[0m, in \u001B[0;36m_pil_png_to_float_array\u001B[1;34m(pil_png)\u001B[0m\n\u001B[0;32m   1729\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mdivide(pil_png\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRGBA\u001B[39m\u001B[38;5;124m\"\u001B[39m), \u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m8\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m   1730\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRGBA\u001B[39m\u001B[38;5;124m\"\u001B[39m:  \u001B[38;5;66;03m# RGBA.\u001B[39;00m\n\u001B[1;32m-> 1731\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdivide\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpil_png\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1732\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown PIL rawmode: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrawmode\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\Learn_Py\\DataSci\\venv\\lib\\site-packages\\PIL\\Image.py:701\u001B[0m, in \u001B[0;36mImage.__array_interface__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    699\u001B[0m         new[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtobytes(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mL\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 701\u001B[0m         new[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtobytes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    703\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, (\u001B[38;5;167;01mMemoryError\u001B[39;00m, \u001B[38;5;167;01mRecursionError\u001B[39;00m)):\n",
      "File \u001B[1;32mD:\\Learn_Py\\DataSci\\venv\\lib\\site-packages\\PIL\\Image.py:758\u001B[0m, in \u001B[0;36mImage.tobytes\u001B[1;34m(self, encoder_name, *args)\u001B[0m\n\u001B[0;32m    755\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m encoder_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m args \u001B[38;5;241m==\u001B[39m ():\n\u001B[0;32m    756\u001B[0m     args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode\n\u001B[1;32m--> 758\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    760\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwidth \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheight \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    761\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32mD:\\Learn_Py\\DataSci\\venv\\lib\\site-packages\\PIL\\ImageFile.py:269\u001B[0m, in \u001B[0;36mImageFile.load\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    266\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(msg)\n\u001B[0;32m    268\u001B[0m b \u001B[38;5;241m=\u001B[39m b \u001B[38;5;241m+\u001B[39m s\n\u001B[1;32m--> 269\u001B[0m n, err_code \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    271\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_dir = 'data_picture'\n",
    "class_names = os.listdir(data_dir)\n",
    "class_names.sort()\n",
    "class_to_index = dict(zip(class_names, range(len(class_names))))\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    for dirpath, _, filenames in os.walk(class_dir):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.png'):\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "                image = plt.imread(filepath)\n",
    "                images.append(image)\n",
    "                labels.append(class_to_index[class_name])\n",
    "\n",
    "# Chia dữ liệu thành các bộ train, validation và test\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Tiền xử lý dữ liệu hình ảnh để chuẩn hóa kích thước và định dạng hình ảnh\n",
    "IMG_SIZE = 128\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Kiểm tra xem ảnh có 4 kênh màu hay không\n",
    "    if image.shape[2] == 4:\n",
    "        # Nếu có, chuyển đổi sang RGB bằng cách bỏ qua kênh alpha\n",
    "        image = image[:,:,:3]\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    return image\n",
    "\n",
    "X_train = np.array([preprocess_image(image) for image in X_train])\n",
    "X_val = np.array([preprocess_image(image) for image in X_val])\n",
    "X_test = np.array([preprocess_image(image) for image in X_test])\n",
    "\n",
    "# Chuyển đổi nhãn sang định dạng one-hot\n",
    "y_train = to_categorical(y_train, len(class_names))\n",
    "y_val = to_categorical(y_val, len(class_names))\n",
    "y_test = to_categorical(y_test, len(class_names))\n",
    "\n",
    "# Xây dựng mô hình CNN\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3),activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile model with categorical crossentropy loss and Adam optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=1e-4), metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate model on test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss:.3f}')\n",
    "print(f'Test accuracy: {test_acc:.3f}')\n",
    "\n",
    "# Visualize accuracy and loss over epochs\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "model.save('CNNs_for_ARS.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang ghi âm...\n",
      "Ghi âm xong!\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import librosa\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "\n",
    "# Tải file trọng số đã huấn luyện\n",
    "model = load_model('CNNs_for_ARS.h5')\n",
    "\n",
    "# Thiết lập tham số ghi âm\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 1.5\n",
    "\n",
    "# Khởi tạo đối tượng PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# Ghi âm đoạn âm thanh\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"Đang ghi âm...\")\n",
    "frames = []\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"Ghi âm xong!\")\n",
    "\n",
    "# Dừng stream và terminate PyAudio\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "# Lưu đoạn ghi âm vào file WAV\n",
    "wf = wave.open(\"output.wav\", \"wb\")\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b\"\".join(frames))\n",
    "wf.close()\n",
    "\n",
    "# Sử dụng librosa để xử lý tín hiệu âm thanh và rút trích đặc trưng\n",
    "y, sr = librosa.load('output.wav', sr=16000)\n",
    "\n",
    "# Trích xuất đặc trưng Mel spectrogram\n",
    "spec = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "\n",
    "# Chuyển đổi sang độ phân giải đồ họa cao hơn\n",
    "S_dB = librosa.power_to_db(spec, ref=np.max)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel', cmap='jet')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('test4.png', bbox_inches='tight', pad_inches=0)\n",
    "plt.close()\n",
    "\n",
    "image = cv2.imread(\"gtdq.png\")\n",
    "prediction = model.predict(np.expand_dims(preprocess_image(image),0))\n",
    "\n",
    "predicted_label = np.argmax(prediction)\n",
    "\n",
    "print(predicted_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['batden', 'batdieuhoa', 'batquat', 'dongcua', 'giamtocdoquat', 'mocua', 'tangtocdoquat', 'tatden', 'tatdieuhoa', 'tatquat']\n"
     ]
    }
   ],
   "source": [
    "print(class_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}